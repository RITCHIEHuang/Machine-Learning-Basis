{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 模型评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.留出法\n",
    "\n",
    "将初始数据集 $D$ 划分为两个互斥的集合$D_{train}$和$D_{test}$,满足\n",
    "$$\n",
    "    D_{train} \\cap D_{test} = \\emptyset \\\\\n",
    "    D_{train} \\cup D_{test} = D\n",
    "$$\n",
    "\n",
    "注意:\n",
    "- 训练集与测试集尽量保持数据分布的一致性 --> 分层采样\n",
    "- 多次划分方式取平均情况（避免划分方式的随机性）\n",
    "- 训练集 : 测试集 (2/3 ~ 4/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../Datasets/iris.data', header = None)\n",
    "# show the first 5 items\n",
    "df.head()\n",
    "# show the last 5 items\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 150 items, unique types: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "y = df.iloc[:, 4].values\n",
    "print(\"dataset has {} items, unique types: {}\".format(len(y), np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to transform the y from characters to some specific label\n",
    "# perform preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we select 2 features, so that we can observe clearly\n",
    "X = df.iloc[:, [2, 3]].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 划分训练集，测试集(使用留出法)\n",
    "取10次的平均情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 : Accuracy : 0.9555555555555556\n",
      "iter 2 : Accuracy : 0.9555555555555556\n",
      "iter 3 : Accuracy : 1.0\n",
      "iter 4 : Accuracy : 0.9555555555555556\n",
      "iter 5 : Accuracy : 0.9555555555555556\n",
      "iter 6 : Accuracy : 0.9555555555555556\n",
      "iter 7 : Accuracy : 1.0\n",
      "iter 8 : Accuracy : 0.9777777777777777\n",
      "iter 9 : Accuracy : 0.9777777777777777\n",
      "iter 10 : Accuracy : 0.9555555555555556\n",
      "Average Accuracy: 0.968888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# StandardScaler perform standardrization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "N = 10\n",
    "scores = 0.0\n",
    "\n",
    "for i in range(N):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "    lr.fit(X_train, y_train)\n",
    "    score = lr.score(X_test, y_test)\n",
    "    \n",
    "    scores = scores + score\n",
    "    print(\"iter {} : Accuracy : {}\".format(i + 1, score))\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores/N))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用交叉验证法(Cross Validation)\n",
    "\n",
    "将初始数据集 $D$ 划分为$k$个互斥的集合$ D_1, D_2, \\cdots, D_k $,满足\n",
    "$$\n",
    "    \\forall \\; i \\neq j, D_i \\cap D_j = \\emptyset \\\\\n",
    "    D_1 \\cup D_2 \\cup \\cdots \\cup D_k = D\n",
    "$$\n",
    "\n",
    "据此规则，有$k$种划分方式，取这$k$次测试结果的平均值.\n",
    "\n",
    "![KFold](KFold.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 交叉验证实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy: 1.0\n",
      "Fold 2: Accuracy: 0.9333333333333333\n",
      "Fold 3: Accuracy: 1.0\n",
      "Fold 4: Accuracy: 0.9333333333333333\n",
      "Fold 5: Accuracy: 0.9333333333333333\n",
      "Fold 6: Accuracy: 0.9333333333333333\n",
      "Fold 7: Accuracy: 0.8666666666666667\n",
      "Fold 8: Accuracy: 1.0\n",
      "Fold 9: Accuracy: 1.0\n",
      "Fold 10: Accuracy: 1.0\n",
      "CV accuracy: 0.96 +/- 0.044221663871405324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, random_state = 1).split(X, y)\n",
    "scores = []\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='auto', C = 100.0, random_state = 1)\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    # X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    lr.fit(X[train], y[train])\n",
    "    score = lr.score(X[test], y[test])\n",
    "    scores.append(score)\n",
    "    print('Fold {}: Accuracy: {}'.format(k + 1, score))\n",
    "\n",
    "print('CV accuracy: {} +/- {}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.自助法\n",
    "\n",
    "放回的抽样选择\n",
    "\n",
    "![BootStrap](BootStrap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 - Accuracy: 0.9821428571428571\n",
      "iter 2 - Accuracy: 0.9649122807017544\n",
      "iter 3 - Accuracy: 0.9464285714285714\n",
      "iter 4 - Accuracy: 0.9591836734693877\n",
      "iter 5 - Accuracy: 0.9818181818181818\n",
      "iter 6 - Accuracy: 0.9642857142857143\n",
      "iter 7 - Accuracy: 0.9672131147540983\n",
      "iter 8 - Accuracy: 0.9629629629629629\n",
      "iter 9 - Accuracy: 0.9361702127659575\n",
      "iter 10 - Accuracy: 1.0\n",
      "BootStrap: Accuracy: 0.9665117569329486 +/- 0.01731566990174846\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def BootStrap(num):\n",
    "    slice = []\n",
    "    while(len(slice) < num):\n",
    "        p = random.randrange(0, num)\n",
    "        slice.append(p)\n",
    "    return slice\n",
    "\n",
    "def getDataByIndex(x, y, index):\n",
    "    xx = []\n",
    "    yy = []\n",
    "    \n",
    "    for i in index:\n",
    "        xx.append(x[i])\n",
    "        yy.append(y[i])\n",
    "        \n",
    "    return xx, yy\n",
    "\n",
    "N = 10\n",
    "N_samples = len(y)\n",
    "all_index = set(range(N_samples))\n",
    "lr = LogisticRegression(solver = 'lbfgs', multi_class = 'auto', C = 100.0, random_state = 1)\n",
    "\n",
    "scores = []\n",
    "for i in range(N):\n",
    "    train_index = BootStrap(N_samples)\n",
    "    unique_index = np.unique(train_index)\n",
    "    test_index = list(all_index - set(unique_index))\n",
    "    \n",
    "    X_train, y_train = getDataByIndex(X, y, train_index)\n",
    "    X_test, y_test = getDataByIndex(X, y, test_index)\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    score = lr.score(X_test, y_test)\n",
    "    \n",
    "    print('iter {} - Accuracy: {}'.format(i + 1, score))\n",
    "    scores.append(score)\n",
    "    \n",
    "print('BootStrap: Accuracy: {} +/- {}'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
